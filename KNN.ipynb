{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a9687cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up all of the 19997 documents in the corpus\n",
    "corpus = sc.textFile (\"s3://chrisjermainebucket/comp330_A6/20_news_same_line.txt\")\n",
    "\n",
    "# each entry in validLines will be a line from the text file\n",
    "validLines = corpus.filter(lambda x : 'id' in x)\n",
    "\n",
    "# now we transform it into a bunch of (docID, text) pairs\n",
    "keyAndText = validLines.map(lambda x : (x[x.index('id=\"') + 4 : x.index('\" url=')], x[x.index('\">') + 2:]))\n",
    "\n",
    "# now we split the text in each (docID, text) pair into a list of words\n",
    "# after this, we have a data set with (docID, [\"word1\", \"word2\", \"word3\", ...])\n",
    "# we have a bit of fancy regular expression stuff here to make sure that we do not\n",
    "# die on some of the documents\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "keyAndListOfWords = keyAndText.map(lambda x : (str(x[0]), regex.sub(' ', x[1]).lower().split()))\n",
    "\n",
    "# now get the top 20,000 words... first change (docID, [\"word1\", \"word2\", \"word3\", ...])\n",
    "# to (\"word1\", 1) (\"word2\", 1)...\n",
    "allWords = keyAndListOfWords.flatMap(lambda x: ((j, 1) for j in x[1]))\n",
    "\n",
    "# now, count all of the words, giving us (\"word1\", 1433), (\"word2\", 3423423), etc.\n",
    "allCounts = allWords.reduceByKey (lambda a, b: a + b)\n",
    "\n",
    "# and get the top 20,000 words in a local array\n",
    "# each entry is a (\"word1\", count) pair\n",
    "topWords = allCounts.top (20000, lambda x : x[1])\n",
    "\n",
    "# and we'll create a RDD that has a bunch of (word, dictNum) pairs\n",
    "# start by creating an RDD that has the number 0 thru 20000\n",
    "# 20000 is the number of words that will be in our dictionary\n",
    "twentyK = sc.parallelize(range(20000))\n",
    "\n",
    "# now, we transform (0), (1), (2), ... to (\"mostcommonword\", 1) (\"nextmostcommon\", 2), ...\n",
    "# the number will be the spot in the dictionary used to tell us where the word is located\n",
    "# HINT: make use of topWords in the lambda that you supply\n",
    "dictionary = twentyK.map (lambda x:(topWords[x][0],x))\n",
    "\n",
    "# finally, print out some of the dictionary, just for debugging\n",
    "dictionary.top (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conversion(tup, dict):\n",
    "#     for x, y in tup:\n",
    "#         dict.setdefault(x, []).append(y)\n",
    "#     return dict\n",
    "\n",
    "# dict = {}\n",
    "# newDict = conversion(topWords, dict)\n",
    "\n",
    "# newDict = dict(topWords)\n",
    "\n",
    "# newDict\n",
    "# {'the': [255140], 'to': [129353], 'of': [116303], 'a': [115484], 'and': [101867], 'i': [93333], 'in': [86847], 'is': [75498], 'that': [70756], 'ax': [62316], 'it': [58760], 'for': [49289], 'you': [48157], 's': [42335], 'from': [39653], 't': [36656], 'on': [35241], 'this': [34691], 'be': [32937], 'not': [32815], 'are': [32220], 'have': [31994], 'with': [30219], 'as': [27911], 'or': [25881], 'edu': [24776], 'was': [24243], 'if': [24232], 'm': [24012], 'but': [23241], 'they': [23203], 'subject': [21589], 'lines': [20891], 'date': [20778], 'doc': [20190], 'can': [20018], 'apr': [19679], 'by': [19545], 're': [18856], 'at': [18490]}\n",
    "\n",
    "# newkeyAndList = dict(keyAndListOfWords)\n",
    "\n",
    "# keyAndListOfWords.top(1)\n",
    "# [('20_newsgroups/talk.religion.misc/84570', ['from', 'pharvey', 'quack', 'kfu', 'com', 'paul', 'harvey', 'subject', 're', 'i', 'll', 'see', 'your', 'demand', 'and', 'raise', 'you', 'was', 're', 'after', 'years', 'etc', 'date', 'apr', 'utc', 'lines', 'in', 'article', 'bil', 'okcforum', 'osrhe', 'edu', 'bill', 'conner', 'writes', 'keith', 'm', 'ryan', 'kmr', 'po', 'cwru', 'edu', 'wrote', 'mand', 'now', 'mdeep', 'thoughts', 'm', 'mby', 'jack', 'handey', 'm', 'mif', 'you', 'go', 'parachuting', 'and', 'your', 'parachute', 'doesn', 't', 'open', 'and', 'your', 'friends', 'are', 'all', 'watching', 'you', 'fall', 'i', 'think', 'a', 'funny', 'gag', 'would', 'be', 'to', 'pretend', 'you', 'were', 'swimming', 'm', 'keith', 'as', 'you', 'must', 'know', 'by', 'now', 'there', 'are', 'no', 'escape', 'sequences', 'here', 'ansi', 'or', 'otherwise', 'once', 'you', 'enter', 'here', 'your', 'terminal', 'beomes', 'dumb', 'there', 's', 'something', 'significant', 'about', 'all', 'this', 'you', 'are', 'in', 'the', 'village', 'many', 'happy', 'returns', 'be', 'seeing', 'you', 'your', 'ways', 'and', 'means', 'get', 'reign', 'of', 'the', 'tek', 'doc'])]\n",
    "\n",
    "# newkeyAndList\n",
    "# {'20_newsgroups/talk.religion.misc/84570': ['from', 'pharvey', 'quack', 'kfu', 'com', 'paul', 'harvey', 'subject', 're', 'i', 'll', 'see', 'your', 'demand', 'and', 'raise', 'you', 'was', 're', 'after', 'years', 'etc', 'date', 'apr', 'utc', 'lines', 'in', 'article', 'bil', 'okcforum', 'osrhe', 'edu', 'bill', 'conner', 'writes', 'keith', 'm', 'ryan', 'kmr', 'po', 'cwru', 'edu', 'wrote', 'mand', 'now', 'mdeep', 'thoughts', 'm', 'mby', 'jack', 'handey', 'm', 'mif', 'you', 'go', 'parachuting', 'and', 'your', 'parachute', 'doesn', 't', 'open', 'and', 'your', 'friends', 'are', 'all', 'watching', 'you', 'fall', 'i', 'think', 'a', 'funny', 'gag', 'would', 'be', 'to', 'pretend', 'you', 'were', 'swimming', 'm', 'keith', 'as', 'you', 'must', 'know', 'by', 'now', 'there', 'are', 'no', 'escape', 'sequences', 'here', 'ansi', 'or', 'otherwise', 'once', 'you', 'enter', 'here', 'your', 'terminal', 'beomes', 'dumb', 'there', 's', 'something', 'significant', 'about', 'all', 'this', 'you', 'are', 'in', 'the', 'village', 'many', 'happy', 'returns', 'be', 'seeing', 'you', 'your', 'ways', 'and', 'means', 'get', 'reign', 'of', 'the', 'tek', 'doc'], '20_newsgroups/talk.religion.misc/84569': ['date', 'tuesday', 'apr', 'edt', 'from', 'subject', 're', 'info', 'about', 'new', 'age', 'lines', 'in', 'article', 'qpalo', 'digi', 'lonestar', 'org', 'gerry', 'palo', 'the', 'danger', 'of', 'anti', 'cult', 'groups', 'is', 'that', 'while', 'they', 'can', 'expose', 'a', 'lot', 'of', 'deception', 'they', 'can', 'also', 'become', 'inquisitors', 'as', 'one', 'who', 'agrees', 'with', 'much', 'of', 'what', 'they', 'say', 'i', 'am', 'also', 'on', 'the', 'receiving', 'end', 'and', 'it', 'makes', 'me', 'realize', 'the', 'importance', 'of', 'respecting', 'the', 'freedom', 'of', 'belief', 'of', 'every', 'individual', 'and', 'also', 'of', 'not', 'jumping', 'to', 'conclusions', 'and', 'making', 'accusations', 'based', 'on', 'a', 'priori', 'assumptions', 'about', 'an', 'individual', 'or', 'group', 'for', 'my', 'money', 'the', 'primary', 'danger', 'of', 'anti', 'cult', 'groups', 'is', 'that', 'they', 'are', 'every', 'bit', 'as', 'wacky', 'as', 'the', 'groups', 'they', 'oppose', 'and', 'that', 'by', 'and', 'large', 'they', 'have', 'no', 'compunctions', 'about', 'printing', 'lies', 'half', 'truths', 'and', 'misleading', 'innuendos', 'as', 'part', 'of', 'their', 'exposes', 'a', 'recent', 'book', 'on', 'cults', 'i', 'picked', 'up', 'by', 'a', 'christian', 'author', 'quite', 'simply', 'mixed', 'in', 'all', 'non', 'christian', 'religions', 'except', 'the', 'jews', 'and', 'various', 'new', 'age', 'groups', 'with', 'various', 'fringe', 'groups', 'of', 'dubious', 'intent', 'and', 'legality', 'on', 'the', 'other', 'hand', 'the', 'watchman', 'fellowship', 'does', 'a', 'good', 'service', 'in', 'exposing', 'deceptive', 'practices', 'that', 'are', 'far', 'too', 'common', 'among', 'the', 'groups', 'they', 'monitor', 'given', 'the', 'record', 'of', 'american', 'christianity', 'any', 'group', 'that', 'falls', 'into', 'the', 'category', 'of', 'fundamentalist', 'or', 'born', 'again', 'is', 'automatically', 'into', 'the', 'inquisition', 'business', 'it', 'is', 'an', 'unavoidable', 'affliction', 'of', 'those', 'who', 'have', 'a', 'proprietary', 'license', 'on', 'the', 'truth', 'and', 'let', 's', 'not', 'forget', 'that', 'jonestown', 'and', 'the', 'branch', 'davidians', 'are', 'just', 'as', 'much', 'a', 'part', 'of', 'the', 'christian', 'tradition', 'as', 'the', 'missouri', 'synod', 'lutherans', 'and', 'may', 'in', 'fact', 'be', 'the', 'massadas', 'of', 'true', 'christian', 'believers', 'i', 'am', 'far', 'more', 'concerned', 'about', 'the', 'encroachment', 'of', 'overtly', 'christian', 'indoctrination', 'into', 'public', 'schools', 'than', 'i', 'am', 'about', 'yoga', 'classes', 'there', 'for', 'those', 'concerned', 'with', 'religious', 'freedom', 'without', 'a', 'selective', 'inquisitiorial', 'bent', 'people', 'for', 'the', 'american', 'way', 'p', 'o', 'box', 'washington', 'dc', 'americans', 'united', 'for', 'separation', 'of', 'church', 'state', 'fenton', 'street', 'silver', 'spring', 'md', 'jack', 'carroll', 'doc']}\n",
    "\n",
    "# id = newkeyAndList.keys()\n",
    "# list = newkeyAndList.values()\n",
    "\n",
    "# ls = []\n",
    "# for x in newkeyAndList:\n",
    "#     eachList = newkeyAndList[x]\n",
    "#     ls.add(eachList)\n",
    "    \n",
    "# for i in newDict:\n",
    "#     for k in ls:\n",
    "#         count_nonzero\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718a7251",
   "metadata": {},
   "source": [
    "task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "newDict = dict(dictionary.top(20000))\n",
    "def list2Array(ls, dic):\n",
    "    word_count = np.zeros(20000)\n",
    "    for word in ls:\n",
    "        try:\n",
    "            word_count[dic[word]] += 1\n",
    "        except:\n",
    "            continue\n",
    "    return word_count\n",
    "result = keyAndListOfWords.map(lambda x:(x[0], list2Array(x[1], newDict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfc04ed",
   "metadata": {},
   "source": [
    "task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464dac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_count = 19997\n",
    "tf = result.map(lambda x: (x[0], x[1] / x[1].sum()))\n",
    "idf_de = result.map(lambda x: (\"idf_de\", np.clip(x[1],0,1)))\n",
    "idf_de = idf_de.reduceByKey(lambda a, b: a + b)\n",
    "idf_de = idf_de.collect()\n",
    "idf = np.log(doc_count/idf_de[0][1])\n",
    "task2_result = tf.map(lambda x: (x[0], x[1] * idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bfa395",
   "metadata": {},
   "source": [
    "task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLabel(k, str):\n",
    "...     str_word = regex.sub(' ', str).lower().split()\n",
    "...     arr_word = list2Array(str_word, newDict)\n",
    "...     tfidf = (arr_word / arr_word.sum()) * idf\n",
    "...     Norm = task2_result.map(lambda x:(x[0], np.linalg.norm(x[1] - tfidf)))\n",
    "...     kNN = Norm.top(k, lambda x: -x[1])\n",
    "...     kNN2 = list(map(lambda x: (x[0][14:], x[1]), kNN))\n",
    "...     kNN3 = list(map(lambda x: (x[0][:x[0].index(\"/\")], x[1]), kNN2))\n",
    "...     kNN4 = list(map(lambda x: x[0], kNN3))\n",
    "...     clo = {}\n",
    "...     for doc in kNN4:\n",
    "...             try:\n",
    "...                     clo[doc] += 1\n",
    "...             except:\n",
    "...                     clo[doc] = 1\n",
    "...     return keyMax(clo)\n",
    "... \n",
    "def keyMax(c):\n",
    "...     v = list(c.values())\n",
    "...     k = list(c.keys())\n",
    "...     return k[v.index(max(v))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
